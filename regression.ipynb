{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "import sys\n",
    "import sklearn.gaussian_process as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(fips):\n",
    "    '''\n",
    "    # Cleaning and retrieving symptoms data\n",
    "    symG = pd.read_csv('covidsymptoms/covidsymptoms_google.csv')\n",
    "    symG = symG.loc[symG['fips'] == float(fips)]\n",
    "    cols = [0,2,3]\n",
    "    symG = symG.drop(symG.columns[cols], axis=1)\n",
    "    \n",
    "    # Cleaning and retrieving symptoms data\n",
    "    symFB = pd.read_csv('covidsymptoms/covidsymptoms_fb.csv')\n",
    "    symFB = symFB.loc[symFB['geo_value'] == float(fips)]\n",
    "    cols = [0,2,3]\n",
    "    symFB = symFB.drop(symFB.columns[cols], axis=1)\n",
    "    \n",
    "    # Cleaning and retrieving testing rate data\n",
    "    tes = pd.read_csv('testingrates/testing_rates_county.csv')\n",
    "    tes = tes.loc[tes['fips'] == float(fips)]\n",
    "    cols = [0]\n",
    "    tes = tes.drop(tes.columns[cols], axis=1)\n",
    "    \n",
    "    # Cleaning and retrieving demographics data\n",
    "    dem = pd.read_csv('countydemographics/county_demographics.csv')\n",
    "    dem = dem.loc[dem['fips'] == float(fips)]\n",
    "    cols = [0,2,3,4,5,6,8,9,10,11]\n",
    "    dem = dem.drop(dem.columns[cols], axis=1)\n",
    "    med_age = dem['median_age'].values[0]\n",
    "    pop_den = dem['Density per square mile of land area'].values[0]\n",
    "    '''\n",
    "    # Cleaning and retrieving mobility data\n",
    "    mob = pd.read_csv('applemobilitydata/applemobilitycleaned_county.csv')\n",
    "    mob = mob.loc[mob['fips'] == float(fips)]\n",
    "    cols = [0,2,3]\n",
    "    mob = mob.drop(mob.columns[cols], axis=1)\n",
    "    \n",
    "    # Cleaning and retrieving GHT data\n",
    "    ght = pd.read_csv('covidsymptoms/googlehealthtrends.csv')\n",
    "    ght = ght.loc[ght['fips'] == float(fips)]\n",
    "    cols = [0,2,3]\n",
    "    ght = ght.drop(ght.columns[cols], axis=1)\n",
    "    \n",
    "    ## Cleaning and retrieving doctor visits data\n",
    "    #doc = pd.read_csv('covidsymptoms/doctorvisits.csv')\n",
    "    #doc = doc.loc[doc['fips'] == float(fips)]\n",
    "    #cols = [0,2,3]\n",
    "    #doc = doc.drop(doc.columns[cols], axis=1)\n",
    "    \n",
    "    # Cleaning and retrieving case data\n",
    "    cas = pd.read_csv('covidstats/confirmed_cases_county.csv')\n",
    "    cas = cas.loc[cas['fips'] == float(fips)]\n",
    "    cols = [0]\n",
    "    cas = cas.drop(cas.columns[cols], axis=1)\n",
    "    \n",
    "    if mob.shape[0] == 0 or ght.shape[0] == 0 or cas.shape[0] == 0:\n",
    "        print('Missing one or more data for county, please use another county.')\n",
    "        return None\n",
    "\n",
    "    return mob, ght, cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(mob, ght, cas):\n",
    "    \n",
    "    newX = pd.concat([mob, ght])\n",
    "    newX = newX.reset_index()\n",
    "    newX = newX.drop(newX.columns[[0,1]], axis=1)\n",
    "    \n",
    "    newY = pd.concat([cas])\n",
    "    newY = newY.reset_index()\n",
    "    newY = newY.drop(newY.columns[[0,1]], axis=1)\n",
    "    \n",
    "    newX = newX.T\n",
    "    newY = newY.T\n",
    "    newX = newX.fillna(0)\n",
    "    newY = newY.fillna(0)\n",
    "    \n",
    "    X = newX[[0,1]]\n",
    "    y = newY[[0]]\n",
    "\n",
    "    # Moving averages\n",
    "\n",
    "    X[0] = X[0].rolling(window=7).mean().dropna()\n",
    "    X[0] = X[0].shift(4).dropna()\n",
    "    X[1] = X[1].shift(12).dropna()\n",
    "    \n",
    "    #y = y.rolling(window=7).mean().dropna()\n",
    "    \n",
    "    X = X[X.index.isin(y.index)]\n",
    "    y = y[y.index.isin(X.index)]\n",
    "    X = X.fillna(0)\n",
    "    y = y.fillna(0)\n",
    "\n",
    "    scaleX = StandardScaler().fit(X)\n",
    "    scaley = StandardScaler().fit(y)\n",
    "    X = scaleX.transform(X)\n",
    "    y = scaley.transform(y)\n",
    "    \n",
    "    return X, y, scaleX, scaley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(fips, county):\n",
    "    X, y, scaleX, scaley = prepareData(*getData(fips))\n",
    "\n",
    "    kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "    regressor = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = regressor.predict(X_train)\n",
    "    y_pred = scaley.inverse_transform(y_pred)\n",
    "    y_train = scaley.inverse_transform(y_train)\n",
    "    y_pred = y_pred.clip(min=0)\n",
    "    \n",
    "    fig = plt.figure() # figsize=(10,10)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(y_train.flatten(), label='Actual')\n",
    "    ax.plot(y_pred.flatten(), label='Predicted')\n",
    "    ax.set_title(f'{county} [TRAINING DATA]')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"2020-01-22 to 2020-04-19\")\n",
    "    plt.ylabel(\"Number of daily cases\")\n",
    "    \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred = scaley.inverse_transform(y_pred)\n",
    "    y_test = scaley.inverse_transform(y_test)\n",
    "    y_pred = y_pred.clip(min=0)\n",
    "    \n",
    "    fig = plt.figure() # figsize=(10,10)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(y_test.flatten(), label='Actual')    \n",
    "    ax.plot(y_pred.flatten(), label='Predicted')\n",
    "    ax.set_title(f'{county} [TESTING DATA]')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"2020-04-20 to 2020-05-27\")\n",
    "    plt.ylabel(\"Predicted number of daily cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('36061', 'New York County')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('22071', 'Orleans, Louisiana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('', 'Erie, New York')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {}\n",
    "def mapping(fips):\n",
    "    try:\n",
    "        passed = getData(fips)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    if not passed:\n",
    "        return None\n",
    "    \n",
    "    X, y, scaleX, scaley = prepareData(*getData(fips))\n",
    "\n",
    "    kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "    regressor = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    y_pred = scaley.inverse_transform(y_pred)\n",
    "    y_test = scaley.inverse_transform(y_test)\n",
    "    y_pred = y_pred.clip(min=0)\n",
    "    \n",
    "    gradient = float((y_pred[-1]-y_pred[0])/(len(y_pred)))\n",
    "    mappings.update({fips:gradient})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = pd.read_csv('county_fips_codes.csv')['fips']\n",
    "for fip in fips:\n",
    "    mapping(str(fip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mappings.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanhFunc(x):\n",
    "  return np.tanh(float(x.values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df.apply(tanhFunc, axis=1)\n",
    "df.columns = ['fips', 'mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('county_prediction_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
